{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b1a666",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"0.1\"></a>\n",
    "# **Prior Uncertainty Quantification (UQ) tools**\n",
    "\n",
    "\n",
    "This notebook contains code examples to quantify uncertainties in precipitation data, including:\n",
    "1. [variability across products](#variability)\n",
    "1. [random errors in individual products](#randomerrors)\n",
    "1. [consistency between data pairs](#consistency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50604a7",
   "metadata": {},
   "source": [
    "<div><img src=\"UQ.png\" width=\"700\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3bb630",
   "metadata": {},
   "source": [
    "## import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df2fe9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rmourad/anaconda3/envs/env_wb/lib/python3.8/site-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob  \n",
    "import gdal\n",
    "import shutil\n",
    "import rasterio as rio \n",
    "import itertools     \n",
    "from itertools import combinations \n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "#import watertools modules\n",
    "import watertools.General.raster_conversions as RC  \n",
    "import watertools.General.data_conversions as DC  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a99fc6e",
   "metadata": {},
   "source": [
    "# 1. variability across products <a class=\"anchor\" id=\"variability\"></a> \n",
    "[Uncertainty Quantification (UQ) tools](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ddf2f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file_info(f_path):\n",
    "    '''\n",
    "    this function gets geospatial information using a raster as a template\n",
    "\n",
    "    inputs:\n",
    "    ----------\n",
    "    - f_path : path to the location of the raster template (str)\n",
    "\n",
    "     outputs:\n",
    "    ----------\n",
    "    - geo_out: geospatial info\n",
    "    - proj: projection \n",
    "    - size_X: grid size in the X dimension\n",
    "    - size_Y: grid size in the Y dimension\n",
    "    \n",
    "    '''\n",
    "    in_fld = sorted(glob.glob(f_path + '/*.tif')) \n",
    "    #print(in_fld)\n",
    "    template = in_fld[0] \n",
    "    print(template)\n",
    "    \n",
    "    geo_out, proj, size_X, size_Y= RC.Open_array_info(template) #using watertools pkg\n",
    "\n",
    "    return geo_out, proj, size_X, size_Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c346b821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/p/chirps/P_CHIRPS.v2.0_mm-month-1_monthly_2003.01.01.tif\n"
     ]
    }
   ],
   "source": [
    "f_path=r'../data/p/chirps'\n",
    "geo_out, proj, size_X, size_Y= extract_file_info(f_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7654921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_annual_avg(root_folder, syear, eyear,output_f):\n",
    "    \"\"\"\n",
    "    this function calculates the long-term annual average of tiff files \n",
    "\n",
    "    inputs:\n",
    "    ----------\n",
    "    - root_folder : path to the root folder (str)\n",
    "    - syear : start year(int) \n",
    "    - eyear : end year (int)\n",
    "    - output_f : location of the output folder (str)\n",
    "\n",
    "    \"\"\"\n",
    "   \n",
    "    for fx in os.listdir(root_folder):\n",
    "        fx_path = os.path.join(root_folder, fx) \n",
    "        if os.path.isdir(fx_path):\n",
    "            fx_sum_arr = None\n",
    "            files = []\n",
    "            num_yrs = eyear - syear + 1\n",
    "            for rx in os.listdir(fx_path):\n",
    "                rx_path = os.path.join(fx_path, rx)\n",
    "                dest_arr = gdal.Open(rx_path)\n",
    "                arr = dest_arr.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "                if fx_sum_arr is None:\n",
    "                    fx_sum_arr = np.zeros_like(arr)\n",
    "                fx_sum_arr += arr\n",
    "\n",
    "                files.append(rx_path)  \n",
    "\n",
    "            annual_avg = fx_sum_arr / num_yrs #long-term annual avg array \n",
    "            out_raster = os.path.join(output_f, f\"{fx}_longterm_avg.tif\")\n",
    "            DC.Save_as_tiff(out_raster, annual_avg,  geo_out, proj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bcc1894",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_f=r'../output_folder/longterm_avg/'\n",
    "root_folder=r'../data/p/'\n",
    "calc_annual_avg(root_folder,2003,2019,output_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd881f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cv(input_fhs, output_f, label=\"CV_p_mm-2003-2019.tif\"):\n",
    "    \"\"\"\n",
    "    this calculates the coefficient of variation (%) across a list long-term annual tiff files\n",
    "\n",
    "     inputs:\n",
    "    ----------\n",
    "    - input_fhs: List of file paths for input rasters  (list)\n",
    "    - output_f : path to the output folder (str)\n",
    "    - label: name of the output raster (str)\n",
    "    \"\"\"\n",
    "    arrs = []\n",
    "\n",
    "    for i in range(len(input_fhs)):\n",
    "        path_in = input_fhs[i]\n",
    "        print(path_in)\n",
    "        dest_arrs = gdal.Open(path_in)\n",
    "        arr = dest_arrs.GetRasterBand(1).ReadAsArray()\n",
    "        arrs.append(arr)\n",
    "        print(arr.shape)\n",
    "\n",
    "    arrs = np.array(arrs) \n",
    "    avg= np.mean(arrs, axis=0) \n",
    "    var = np.mean((arrs - avg) ** 2, axis=0) \n",
    "    std = np.sqrt(var) #std\n",
    "    cv = (std / avg) * 100 #CV(%)\n",
    "\n",
    "    fh_out = os.path.join(output_f, label)\n",
    "    DC.Save_as_tiff(fh_out, cv,  geo_out, proj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a7ec49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output_folder/longterm_avg/chirps_longterm_avg.tif\n",
      "(37, 13)\n",
      "../output_folder/longterm_avg/gpm_longterm_avg.tif\n",
      "(37, 13)\n",
      "../output_folder/longterm_avg/mswep_longterm_avg.tif\n",
      "(37, 13)\n",
      "../output_folder/longterm_avg/trmm_longterm_avg.tif\n",
      "(37, 13)\n"
     ]
    }
   ],
   "source": [
    "input_fhs=sorted(glob.glob(output_f+'/*.tif'))\n",
    "output_cv=r'../output_folder/cv'\n",
    "calc_cv (input_fhs, output_cv, label=\"CV_p_mm-2003-2019.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6808341",
   "metadata": {},
   "source": [
    "# 2. random errors in individual products <a class=\"anchor\" id=\"randomerrors\"></a> \n",
    "[Uncertainty Quantification (UQ) tools](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "229e178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dirs(path_root):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    ----------\n",
    "    - path_root: path for dirs (str) \n",
    "    \n",
    "    outputs:\n",
    "    ----------\n",
    "    - list of dirs paths\n",
    "\n",
    "    \"\"\"\n",
    "    dirs_data = [os.path.join(path_root, dx) for dx in os.listdir(path_root)]\n",
    "    return dirs_data\n",
    "\n",
    "def make_dict_data(dirs_data):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    ----------\n",
    "    - dirs_data: list of data dirs paths\n",
    "    \n",
    "    outputs:\n",
    "    ----------\n",
    "    - dict_data: a dictionary with dir names as keys and file paths as values\n",
    "    - dict_ts: a dictionary of stacke timeseries data \n",
    "    \n",
    "    \"\"\"\n",
    "    dict_data = {}\n",
    "    dict_ts = {}\n",
    "\n",
    "\n",
    "    for dx in dirs_data:\n",
    "        if not os.path.isdir(dx):\n",
    "            continue\n",
    "        fxs_list = [os.path.join(dx, f) for f in sorted(os.listdir(dx)) ] #list of files\n",
    "        dir_label= os.path.split(dx)[1]\n",
    "        dict_data[dir_label] = fxs_list\n",
    "        \n",
    "    #CHECK WHETHER ARRAYS HAVE CONSISTENT LENGTHS\n",
    "    leng = {label: len(paths) for label, paths in dict_data.items()}  \n",
    "    #print(leng) \n",
    "\n",
    "        \n",
    "    for k in dict_data.keys():\n",
    "        #print(k)\n",
    "        for fx in range(len(fxs_list)):\n",
    "            arr_3d = np.dstack([rio.open(d).read(1) for d in dict_data[k]])\n",
    "            dict_ts[k] = arr_3d\n",
    "    \n",
    "    return dict_data,dict_ts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ac61815",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs_data=list_dirs(\"../data/p/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43dc4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data,dict_ts=make_dict_data(dirs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "345b89af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_rescaling(source_dataset, ref_dataset):\n",
    "    '''\n",
    "    this function scales the source data set to the mean and std of a reference data set\n",
    "\n",
    "    inputs:\n",
    "    ----------\n",
    "    - source_dataset to be scaled \n",
    "    - ref_dataset to be used as template\n",
    "\n",
    "    outputs:\n",
    "    ----------\n",
    "    - scaled dataset\n",
    "    \n",
    "    references\n",
    "    ----------\n",
    "    linear rescaling Eq 2 in:\n",
    "    --Brocca, L., Melone, F., Moramarco, T., Wagner, W., & Hasenauer, S. (2010). \n",
    "      ASCAT soil wetness index validation through in situ and \n",
    "      modeled soil moisture data in central Italy. \n",
    "      Remote Sensing of Environment, 114(11), 2745-2755.\n",
    "      \n",
    "    other alternative rescaling options include: \n",
    "    - forcing source data set to have the same min and max as the ref data set\n",
    "    - matching the cumulative distribution function (CDF) of the source data set with that of ref data set\n",
    "    as in Eqs 6 & 7 in: \n",
    "    --Wu, K., Ryu, D., Wagner, W., & Hu, Z. (2023).\n",
    "      A global-scale intercomparison of Triple Collocation Analysis-and ground-based \n",
    "      soil moisture time-variant errors derived from different rescaling techniques.\n",
    "      Remote Sensing of Environment, 285, 113387.\n",
    "    \n",
    "    '''\n",
    "    return ((source_dataset - np.nanmean(source_dataset)) / np.nanstd(source_dataset)) * np.nanstd(ref_dataset) + np.nanmean(ref_dataset)\n",
    "\n",
    "\n",
    "def compute_random_errors(A,B,C):\n",
    "    '''\n",
    "    this function computes random errors as std of the noise error in individual products \n",
    "    \n",
    "    inputs:\n",
    "    ----------\n",
    "    - triplet data sets: A, B & C \n",
    "     where A, B and C are three spatially and temporally collocated data sets\n",
    "    \n",
    "    outputs:\n",
    "    ----------\n",
    "    - error std\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    std_A = np.sqrt(np.abs(np.nanmean((A - B) * (A - C))))\n",
    "    std_B = np.sqrt(np.abs(np.nanmean((B - A) * (B - C))))\n",
    "    std_C = np.sqrt(np.abs(np.nanmean((C - A) * (C - B))))\n",
    "\n",
    "    return std_A, std_B, std_C\n",
    "\n",
    "def compute_errs_combos(dict_ts, combos):\n",
    "    '''\n",
    "    this function computes errors for all combinations of triplets \n",
    "    a wrapper for compute_random_errors\n",
    "    \n",
    "    inputs:\n",
    "    ----------\n",
    "    - dict_ts:timeseries data (dict)\n",
    "    - combos: all possible combinations of triplets\n",
    "    \n",
    "    outputs:\n",
    "    ----------\n",
    "    - errors: spatial std of errors in individual product \n",
    "    \n",
    "    references\n",
    "    ----------\n",
    "    – To solve for the standard deciation, std is computed as proposed by Stoffelen (1998)** \n",
    "    – by averaging the cross-multiplied differences between the three a-priori rescaled data sets.\n",
    "    - Stoffelen (1998) also proposed other formulation based on combinations of the covariances\n",
    "      between the data sets. However, both approaches are mathematically identical.\n",
    "    \n",
    "    **Stoffelen, A. (1998). Toward the true near‐surface wind speed: Error modeling and calibration \n",
    "    using triple collocation.Journal of geophysical research: oceans, 103(C4), 7755-7766.\n",
    "    \n",
    "    '''\n",
    "    errs = {f'{map_combo[0]}_{z}': {\n",
    "                f'{map_combo[0]}_{z}': np.zeros_like(dict_ts[map_combo[0]][:, :, 0]),\n",
    "                f'{map_combo[1]}_{z}': np.zeros_like(dict_ts[map_combo[1]][:, :, 0]),\n",
    "                f'{map_combo[2]}_{z}': np.zeros_like(dict_ts[map_combo[2]][:, :, 0])} \n",
    "              for z, map_combo in enumerate(combos)}\n",
    "\n",
    "    for i in range(errs[f'{combos_labels[0]}_0'][f'{combos_labels[0]}_0'].shape[0]):\n",
    "        for j in range(errs[f'{combos_labels[0]}_0'][f'{combos_labels[0]}_0'].shape[1]):\n",
    "            for x, map_combo in enumerate(combos):\n",
    "                A_label = f'{map_combo[0]}_{x}'\n",
    "                val_A = dict_ts[map_combo[0]][i, j, :]\n",
    "                val_B = dict_ts[map_combo[1]][i, j, :]\n",
    "                val_C = dict_ts[map_combo[2]][i, j, :]\n",
    "                \n",
    "                std_A, std_B, std_C= compute_random_errors(val_A, linear_rescaling(val_B, val_A), linear_rescaling(val_C, val_A))\n",
    "                \n",
    "                errs[A_label][f'{map_combo[0]}_{x}'][i, j] = std_A\n",
    "                errs[A_label][f'{map_combo[1]}_{x}'][i, j] = std_B\n",
    "                errs[A_label][f'{map_combo[2]}_{x}'][i, j] = std_C\n",
    "\n",
    "    return errs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "346b6468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k7/s9nsfw2n2xn2wt1s8hdszh8m0000gn/T/ipykernel_41284/879367388.py:32: RuntimeWarning: Mean of empty slice\n",
      "  return ((source_dataset - np.nanmean(source_dataset)) / np.nanstd(source_dataset)) * np.nanstd(ref_dataset) + np.nanmean(ref_dataset)\n",
      "/Users/rmourad/anaconda3/envs/env_wb/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/var/folders/k7/s9nsfw2n2xn2wt1s8hdszh8m0000gn/T/ipykernel_41284/879367388.py:50: RuntimeWarning: Mean of empty slice\n",
      "  std_A = np.sqrt(np.abs(np.nanmean((A - B) * (A - C))))\n",
      "/var/folders/k7/s9nsfw2n2xn2wt1s8hdszh8m0000gn/T/ipykernel_41284/879367388.py:51: RuntimeWarning: Mean of empty slice\n",
      "  std_B = np.sqrt(np.abs(np.nanmean((B - A) * (B - C))))\n",
      "/var/folders/k7/s9nsfw2n2xn2wt1s8hdszh8m0000gn/T/ipykernel_41284/879367388.py:52: RuntimeWarning: Mean of empty slice\n",
      "  std_C = np.sqrt(np.abs(np.nanmean((C - A) * (C - B))))\n"
     ]
    }
   ],
   "source": [
    "combos_labels = ['chirps', 'gpm', 'mswep','trmm']  \n",
    "map_combo = list(itertools.permutations(combos_labels, 3))\n",
    "\n",
    "random_errors = compute_errs_combos(dict_ts, map_combo) #calc errors for all combos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f61c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_errors_to_tifs(out_f, random_errors):\n",
    "    '''\n",
    "    this function outputs errors to tiff files\n",
    "\n",
    "    inputs:\n",
    "    ----------\n",
    "    - out_f : output folder (str)\n",
    "    - random_errors (dict) \n",
    "\n",
    "    '''\n",
    "    for k,val in random_errors.items():\n",
    "        for arr_k, arr_data in val.items():\n",
    "            label_outfile = os.path.join(out_f, f\"{arr_k}.tif\")\n",
    "            DC.Save_as_tiff(label_outfile, arr_data, geo_out, proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "363c31b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder=r'../output_folder/TC'\n",
    "save_errors_to_tifs(output_folder,random_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6d4cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_rasters_in_subfold(f_path, ext='.tif', extr=2):\n",
    "    '''\n",
    "    this function stores tiff files in subfolders using their labels\n",
    "\n",
    "    inputs:\n",
    "    ----------\n",
    "    - f_path : path to tiff files\n",
    "    - ext : tiff files extension (str)\n",
    "    - extr : characters extracted from the filelabel(int) \n",
    "\n",
    "    '''\n",
    "    for filelabel in os.listdir(f_path):\n",
    "        if filelabel.endswith(ext):\n",
    "            label= filelabel[:extr]\n",
    "            subfold = os.path.join(f_path, label)\n",
    "            os.makedirs(subfold, exist_ok=True)\n",
    "            shutil.move(os.path.join(f_path, filelabel), os.path.join(subfold, filelabel))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "626bad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_rasters_in_subfold(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "762a3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the subfolders\n",
    "\n",
    "for f_label in os.listdir(output_folder):\n",
    "    if f_label == 'ch':\n",
    "        os.rename(os.path.join(output_folder, f_label), os.path.join(output_folder, 'chirps'))\n",
    "    elif f_label == 'ms':\n",
    "        os.rename(os.path.join(output_folder, f_label), os.path.join(output_folder, 'mswep'))\n",
    "    elif f_label == 'tr':\n",
    "        os.rename(os.path.join(output_folder, f_label), os.path.join(output_folder, 'trmm'))\n",
    "    elif f_label == 'gp':\n",
    "        os.rename(os.path.join(output_folder, f_label), os.path.join(output_folder,'gpm'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7396958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_error(root_folder):\n",
    "    '''\n",
    "    this function computes the average error for list of triple collocation error tiff files\n",
    "\n",
    "    inputs:\n",
    "    ----------\n",
    "    root_folder: path to the error tiff files (str)\n",
    "    \n",
    "    '''\n",
    "    for fhs_label in os.listdir(root_folder):\n",
    "        fhs = os.path.join(root_folder, fhs_label)\n",
    "\n",
    "        if os.path.isdir(fhs):\n",
    "            sum_arr = None\n",
    "            fr = []\n",
    "\n",
    "            for rx in os.listdir(fhs):\n",
    "                rx_path = os.path.join(fhs, rx)\n",
    "                #print(rx_path)\n",
    "                fr.append(rx_path)  # Append the raster file path to the list\n",
    "                img = gdal.Open(rx_path)  # Open the raster file\n",
    "                arr = img.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "                # update sum_arr\n",
    "                if sum_arr is None:\n",
    "                    sum_arr = np.zeros_like(arr)\n",
    "\n",
    "                sum_arr += arr\n",
    "\n",
    "            # calculate the avg\n",
    "            arr_avg = sum_arr / len(fr)\n",
    "\n",
    "            geo_out, proj, size_X, size_Y = extract_file_info(f_path)\n",
    "\n",
    "            # save output\n",
    "            output_label = os.path.join(fhs, f\"TC_{fhs_label}_avg.tif\")\n",
    "            DC.Save_as_tiff(output_label, arr_avg, geo_out, proj)  # Save raster \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a0cad3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/p/chirps/P_CHIRPS.v2.0_mm-month-1_monthly_2003.01.01.tif\n",
      "../data/p/chirps/P_CHIRPS.v2.0_mm-month-1_monthly_2003.01.01.tif\n",
      "../data/p/chirps/P_CHIRPS.v2.0_mm-month-1_monthly_2003.01.01.tif\n",
      "../data/p/chirps/P_CHIRPS.v2.0_mm-month-1_monthly_2003.01.01.tif\n"
     ]
    }
   ],
   "source": [
    "compute_avg_error(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8736a9f",
   "metadata": {},
   "source": [
    "# 3. consistency between data pairs <a class=\"anchor\" id=\"consistency\"></a> \n",
    "[Uncertainty Quantification (UQ) tools](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52eba689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_monthly_avg(r_f, outf_p, syear, eyear):\n",
    "    \"\"\"\n",
    "    this function computes the long-term monthly average of tiff files\n",
    "\n",
    "    inputs:\n",
    "    ----------\n",
    "    - r_f: path to the root folder (str)\n",
    "    - outf_p : output folder to store avg monthly tiff files(str)\n",
    "    - syear : start year(int)\n",
    "    - eyear : end year(int)\n",
    "    \"\"\"\n",
    "    yrs_nb = eyear - syear + 1\n",
    "    mths = range(1, 13)\n",
    "\n",
    "    for subf_label in os.listdir(r_f):\n",
    "        fhs = os.path.join(r_f, subf_label)\n",
    "\n",
    "        if os.path.isdir(fhs):\n",
    "            m_avgs = {}\n",
    "\n",
    "            for rx in os.listdir(fhs):\n",
    "                rx_path = os.path.join(fhs, rx)\n",
    "\n",
    "                dest_arr = gdal.Open(rx_path)\n",
    "                arr = dest_arr.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "                m = int(rx[-9:-7])\n",
    "                #print(m)\n",
    "\n",
    "                # aggregate\n",
    "                if m in m_avgs:\n",
    "                    m_avgs[m].append(arr)\n",
    "                else:\n",
    "                    m_avgs[m] = [arr]\n",
    "                    \n",
    "            fhs_output= os.path.join(outf_p, subf_label)\n",
    "            os.makedirs(fhs_output, exist_ok=True)\n",
    "\n",
    "            for m,x in m_avgs.items():\n",
    "                m_mean = np.mean(x, axis=0)\n",
    "                output_label = os.path.join(fhs_output, f'{subf_label}_avg_{m:02d}.tif')\n",
    "                DC.Save_as_tiff(output_label, m_mean, geo_out, proj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c591d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "outf_p=r'../output_folder/monthly_longterm_avg'\n",
    "compute_monthly_avg(root_folder, outf_p, 2003, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70f25d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../output_folder/longterm_avg/chirps_longterm_avg.tif', '../output_folder/longterm_avg/gpm_longterm_avg.tif', '../output_folder/longterm_avg/mswep_longterm_avg.tif', '../output_folder/longterm_avg/trmm_longterm_avg.tif']\n",
      "     row  col  chirps_longterm_avg_val  gpm_longterm_avg_val  \\\n",
      "11     0   11              1419.768066           1466.187256   \n",
      "23     1   10              1418.300293           1406.040649   \n",
      "24     1   11              1412.772339           1427.168213   \n",
      "35     2    9              1263.947266           1352.552002   \n",
      "36     2   10              1311.729614           1375.716309   \n",
      "..   ...  ...                      ...                   ...   \n",
      "446   34    4               861.020447            884.861084   \n",
      "447   34    5               852.606934            885.286255   \n",
      "459   35    4               836.936768            868.385376   \n",
      "460   35    5               828.406067            870.664551   \n",
      "472   36    4               844.303040            854.458862   \n",
      "\n",
      "     mswep_longterm_avg_val  trmm_longterm_avg_val  \n",
      "11              1691.985718            1466.706055  \n",
      "23              1555.549561            1399.857178  \n",
      "24              1593.652588            1424.922363  \n",
      "35              1436.382935            1325.330200  \n",
      "36              1451.153320            1352.153320  \n",
      "..                      ...                    ...  \n",
      "446              839.233459             729.890198  \n",
      "447              850.931396             735.751831  \n",
      "459              824.186279             727.025879  \n",
      "460              835.187927             732.518066  \n",
      "472              810.452881             724.605408  \n",
      "\n",
      "[221 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#extract pixel by pixel value from long-term annual rasters\n",
    "# df\n",
    "output_f=r'../output_folder/longterm_avg/'\n",
    "output_f_p=sorted(glob.glob(output_f+'/*.tif')) #get list of tif files in the output_f folder\n",
    "print(output_f_p)\n",
    "df = pd.DataFrame(columns=['row', 'col'] + [os.path.splitext(os.path.basename(rx))[0] + '_val' for rx in output_f_p], dtype='object')\n",
    "\n",
    "for i, rx in enumerate(output_f_p):\n",
    "    #print(rx)\n",
    "    # Open the raster file\n",
    "    img = gdal.Open(rx)\n",
    "    data = img.GetRasterBand(1).ReadAsArray()  \n",
    "    idx, jdx = data.shape\n",
    "    #print(idx, jdx)\n",
    "    i_ind, j_ind = zip(*[(i, j) for i in range(idx) for j in range(jdx)])\n",
    "    \n",
    "    rx_label = os.path.splitext(os.path.basename(rx))[0]\n",
    "    df[f'{rx_label}_val'] = data.flatten()\n",
    "    df['row'] = i_ind\n",
    "    df['col'] = j_ind \n",
    "\n",
    "df_annual = df[['row', 'col'] + [f'{os.path.splitext(os.path.basename(rx))[0]}_val' for rx in output_f_p]]\n",
    "df_annual=df_annual.dropna()\n",
    "print(df_annual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2eef4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var   row  col month  chirps_val     gpm_val   mswep_val    trmm_val\n",
      "0       0   11    01   37.980198   59.296261   41.447906   62.900562\n",
      "1       0   11    02   46.546814   46.641949   49.457245   61.216122\n",
      "2       0   11    03   44.627460   43.122433   38.775211   40.940525\n",
      "3       0   11    04   21.511440   30.202282   26.348068   32.613499\n",
      "4       0   11    05   30.734367   39.504498   36.736843   36.886265\n",
      "...   ...  ...   ...         ...         ...         ...         ...\n",
      "2647   36    4    08  240.456345  231.957367  218.106476  180.060471\n",
      "2648   36    4    09  180.250000  155.690353  127.589211  123.292236\n",
      "2649   36    4    10   20.838272   18.132839   15.366764   17.345369\n",
      "2650   36    4    11    3.061043    5.250890    4.227652    3.091552\n",
      "2651   36    4    12    7.615211    3.761159    4.948952    3.583566\n",
      "\n",
      "[2652 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#extract pixel by pixel value from long-term monthly rasters\n",
    "outfolder_P = r'../output_folder/monthly_longterm_avg'\n",
    "list_data = []\n",
    "# Loop over subfolders in the main folder\n",
    "for fhs in os.listdir(outfolder_P):\n",
    "    fhs_path = os.path.join(outfolder_P, fhs)\n",
    "    rx_data = sorted(glob.glob(os.path.join(fhs_path, '*.tif')))\n",
    "\n",
    "    for i, rx in enumerate(rx_data):\n",
    "        img = gdal.Open(rx)\n",
    "        data= img.GetRasterBand(1).ReadAsArray()\n",
    "        idx, jdx = data.shape\n",
    "        i_ind, j_ind = zip(*[(i, j) for i in range(idx) for j in range(jdx)])\n",
    "        m = os.path.splitext(os.path.basename(rx))[0][-2:] #extract month\n",
    "        list_data.extend(list(zip(i_ind, j_ind, [m] * len(i_ind), [f'{fhs}_val'] * len(i_ind), data.flatten())))\n",
    "\n",
    "# df\n",
    "col_labels = ['row', 'col', 'month', 'var', 'val']\n",
    "df_month = pd.DataFrame(list_data, columns=col_labels)\n",
    "df_month = df_month.pivot_table(index=['row', 'col', 'month'], columns='var', values='val').reset_index()\n",
    "print(df_month.dropna())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0006f8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spatial_R2(A, B):\n",
    "    A = np.array(A)\n",
    "    B = np.array(B)\n",
    "    a, b = np.polyfit(A, B, 1)\n",
    "    B_pred = a * A + b\n",
    "    R2 = r2_score(B, B_pred)\n",
    "    return {'R2': R2}\n",
    "\n",
    "def do_R2_annual_pairs(df):\n",
    "    \n",
    "    dict_yr = df.astype(float).to_dict('list') \n",
    "    combos = list(itertools.combinations(dict_yr, 2))\n",
    "\n",
    "    res = {}\n",
    "\n",
    "    for idx, i in enumerate(combos):\n",
    "        A = dict_yr[i[0]]\n",
    "        B = dict_yr[i[1]]\n",
    "        R2_metric = compute_spatial_R2(A, B)\n",
    "        res[i] = R2_metric\n",
    "    return res\n",
    "\n",
    "def do_R2_month_pairs(df):\n",
    "    '''\n",
    "    this function computes R2 metric by a month column applied to df\n",
    "    '''\n",
    "    res = {}\n",
    "\n",
    "    # Group the data by month column\n",
    "    m_grp = df.groupby('month')\n",
    "    for m, grp in m_grp:\n",
    "        dict_m = grp.astype(float).to_dict('list')\n",
    "        combos = list(itertools.combinations(dict_m, 2))\n",
    "        for idx, i in enumerate(combos):\n",
    "            A = dict_m[i[0]]\n",
    "            B = dict_m[i[1]]\n",
    "            R2_metric = compute_spatial_R2(A, B)\n",
    "            # store R2 with the month as an identifier\n",
    "            res[(m, i)] = R2_metric\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48e588cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k7/s9nsfw2n2xn2wt1s8hdszh8m0000gn/T/ipykernel_41284/191048470.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p_yr_df.rename(columns = p_yr_dict, inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chirps</th>\n",
       "      <th>gpm</th>\n",
       "      <th>mswep</th>\n",
       "      <th>trmm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1419.768066</td>\n",
       "      <td>1466.187256</td>\n",
       "      <td>1691.985718</td>\n",
       "      <td>1466.706055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1418.300293</td>\n",
       "      <td>1406.040649</td>\n",
       "      <td>1555.549561</td>\n",
       "      <td>1399.857178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1412.772339</td>\n",
       "      <td>1427.168213</td>\n",
       "      <td>1593.652588</td>\n",
       "      <td>1424.922363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1263.947266</td>\n",
       "      <td>1352.552002</td>\n",
       "      <td>1436.382935</td>\n",
       "      <td>1325.330200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1311.729614</td>\n",
       "      <td>1375.716309</td>\n",
       "      <td>1451.153320</td>\n",
       "      <td>1352.153320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>861.020447</td>\n",
       "      <td>884.861084</td>\n",
       "      <td>839.233459</td>\n",
       "      <td>729.890198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>852.606934</td>\n",
       "      <td>885.286255</td>\n",
       "      <td>850.931396</td>\n",
       "      <td>735.751831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>836.936768</td>\n",
       "      <td>868.385376</td>\n",
       "      <td>824.186279</td>\n",
       "      <td>727.025879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>828.406067</td>\n",
       "      <td>870.664551</td>\n",
       "      <td>835.187927</td>\n",
       "      <td>732.518066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>844.303040</td>\n",
       "      <td>854.458862</td>\n",
       "      <td>810.452881</td>\n",
       "      <td>724.605408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          chirps          gpm        mswep         trmm\n",
       "11   1419.768066  1466.187256  1691.985718  1466.706055\n",
       "23   1418.300293  1406.040649  1555.549561  1399.857178\n",
       "24   1412.772339  1427.168213  1593.652588  1424.922363\n",
       "35   1263.947266  1352.552002  1436.382935  1325.330200\n",
       "36   1311.729614  1375.716309  1451.153320  1352.153320\n",
       "..           ...          ...          ...          ...\n",
       "446   861.020447   884.861084   839.233459   729.890198\n",
       "447   852.606934   885.286255   850.931396   735.751831\n",
       "459   836.936768   868.385376   824.186279   727.025879\n",
       "460   828.406067   870.664551   835.187927   732.518066\n",
       "472   844.303040   854.458862   810.452881   724.605408\n",
       "\n",
       "[221 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_yr_dict = {'chirps_longterm_avg_val':'chirps',\n",
    "             'gpm_longterm_avg_val': 'gpm',\n",
    "             'mswep_longterm_avg_val':'mswep', \n",
    "             'trmm_longterm_avg_val':'trmm'}\n",
    "    \n",
    "p_yr_df= df_annual.loc[:, df_annual.columns.isin(p_yr_dict.keys())]\n",
    "p_yr_df.rename(columns = p_yr_dict, inplace = True)\n",
    "p_yr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c37251e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chirps</th>\n",
       "      <th>gpm</th>\n",
       "      <th>mswep</th>\n",
       "      <th>trmm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1419.768066</td>\n",
       "      <td>1466.187256</td>\n",
       "      <td>1691.985718</td>\n",
       "      <td>1466.706055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1418.300293</td>\n",
       "      <td>1406.040649</td>\n",
       "      <td>1555.549561</td>\n",
       "      <td>1399.857178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1412.772339</td>\n",
       "      <td>1427.168213</td>\n",
       "      <td>1593.652588</td>\n",
       "      <td>1424.922363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1263.947266</td>\n",
       "      <td>1352.552002</td>\n",
       "      <td>1436.382935</td>\n",
       "      <td>1325.330200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1311.729614</td>\n",
       "      <td>1375.716309</td>\n",
       "      <td>1451.153320</td>\n",
       "      <td>1352.153320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>861.020447</td>\n",
       "      <td>884.861084</td>\n",
       "      <td>839.233459</td>\n",
       "      <td>729.890198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>852.606934</td>\n",
       "      <td>885.286255</td>\n",
       "      <td>850.931396</td>\n",
       "      <td>735.751831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>836.936768</td>\n",
       "      <td>868.385376</td>\n",
       "      <td>824.186279</td>\n",
       "      <td>727.025879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>828.406067</td>\n",
       "      <td>870.664551</td>\n",
       "      <td>835.187927</td>\n",
       "      <td>732.518066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>844.303040</td>\n",
       "      <td>854.458862</td>\n",
       "      <td>810.452881</td>\n",
       "      <td>724.605408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          chirps          gpm        mswep         trmm\n",
       "11   1419.768066  1466.187256  1691.985718  1466.706055\n",
       "23   1418.300293  1406.040649  1555.549561  1399.857178\n",
       "24   1412.772339  1427.168213  1593.652588  1424.922363\n",
       "35   1263.947266  1352.552002  1436.382935  1325.330200\n",
       "36   1311.729614  1375.716309  1451.153320  1352.153320\n",
       "..           ...          ...          ...          ...\n",
       "446   861.020447   884.861084   839.233459   729.890198\n",
       "447   852.606934   885.286255   850.931396   735.751831\n",
       "459   836.936768   868.385376   824.186279   727.025879\n",
       "460   828.406067   870.664551   835.187927   732.518066\n",
       "472   844.303040   854.458862   810.452881   724.605408\n",
       "\n",
       "[221 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_yr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "600eb547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('chirps', 'gpm'): {'R2': 0.8135625653043942},\n",
       " ('chirps', 'mswep'): {'R2': 0.860958638868887},\n",
       " ('chirps', 'trmm'): {'R2': 0.8348133706694025},\n",
       " ('gpm', 'mswep'): {'R2': 0.9324396555332763},\n",
       " ('gpm', 'trmm'): {'R2': 0.9586354525927328},\n",
       " ('mswep', 'trmm'): {'R2': 0.9807892099038125}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_R2_annual_pairs(p_yr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "305cb4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k7/s9nsfw2n2xn2wt1s8hdszh8m0000gn/T/ipykernel_41284/2019154241.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p_m_df.rename(columns = p_m_dict, inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>var</th>\n",
       "      <th>chirps</th>\n",
       "      <th>gpm</th>\n",
       "      <th>mswep</th>\n",
       "      <th>trmm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>37.980198</td>\n",
       "      <td>59.296261</td>\n",
       "      <td>41.447906</td>\n",
       "      <td>62.900562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>46.546814</td>\n",
       "      <td>46.641949</td>\n",
       "      <td>49.457245</td>\n",
       "      <td>61.216122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <td>44.627460</td>\n",
       "      <td>43.122433</td>\n",
       "      <td>38.775211</td>\n",
       "      <td>40.940525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04</th>\n",
       "      <td>21.511440</td>\n",
       "      <td>30.202282</td>\n",
       "      <td>26.348068</td>\n",
       "      <td>32.613499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05</th>\n",
       "      <td>30.734367</td>\n",
       "      <td>39.504498</td>\n",
       "      <td>36.736843</td>\n",
       "      <td>36.886265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08</th>\n",
       "      <td>240.456345</td>\n",
       "      <td>231.957367</td>\n",
       "      <td>218.106476</td>\n",
       "      <td>180.060471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09</th>\n",
       "      <td>180.250000</td>\n",
       "      <td>155.690353</td>\n",
       "      <td>127.589211</td>\n",
       "      <td>123.292236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20.838272</td>\n",
       "      <td>18.132839</td>\n",
       "      <td>15.366764</td>\n",
       "      <td>17.345369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.061043</td>\n",
       "      <td>5.250890</td>\n",
       "      <td>4.227652</td>\n",
       "      <td>3.091552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.615211</td>\n",
       "      <td>3.761159</td>\n",
       "      <td>4.948952</td>\n",
       "      <td>3.583566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2652 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "var        chirps         gpm       mswep        trmm\n",
       "month                                                \n",
       "01      37.980198   59.296261   41.447906   62.900562\n",
       "02      46.546814   46.641949   49.457245   61.216122\n",
       "03      44.627460   43.122433   38.775211   40.940525\n",
       "04      21.511440   30.202282   26.348068   32.613499\n",
       "05      30.734367   39.504498   36.736843   36.886265\n",
       "...           ...         ...         ...         ...\n",
       "08     240.456345  231.957367  218.106476  180.060471\n",
       "09     180.250000  155.690353  127.589211  123.292236\n",
       "10      20.838272   18.132839   15.366764   17.345369\n",
       "11       3.061043    5.250890    4.227652    3.091552\n",
       "12       7.615211    3.761159    4.948952    3.583566\n",
       "\n",
       "[2652 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_m_dict = {'chirps_val':'chirps',\n",
    "             'gpm_val': 'gpm',\n",
    "             'mswep_val':'mswep', \n",
    "             'trmm_val':'trmm',\n",
    "             'month':'month'}\n",
    "    \n",
    "p_m_df= df_month.loc[:, df_month.columns.isin(p_m_dict.keys())]\n",
    "p_m_df.rename(columns = p_m_dict, inplace = True)\n",
    "p_m_df.set_index('month', inplace=True)\n",
    "p_m_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51c9fd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('01', ('chirps', 'gpm')): {'R2': 0.9117175176420835},\n",
       " ('01', ('chirps', 'mswep')): {'R2': 0.8380546688725639},\n",
       " ('01', ('chirps', 'trmm')): {'R2': 0.7100072656857284},\n",
       " ('01', ('gpm', 'mswep')): {'R2': 0.9577343192988783},\n",
       " ('01', ('gpm', 'trmm')): {'R2': 0.8862834214570792},\n",
       " ('01', ('mswep', 'trmm')): {'R2': 0.9653490511347538},\n",
       " ('02', ('chirps', 'gpm')): {'R2': 0.7156481131995412},\n",
       " ('02', ('chirps', 'mswep')): {'R2': 0.7182622937670498},\n",
       " ('02', ('chirps', 'trmm')): {'R2': 0.812094399837707},\n",
       " ('02', ('gpm', 'mswep')): {'R2': 0.9227742637918978},\n",
       " ('02', ('gpm', 'trmm')): {'R2': 0.9412955162195374},\n",
       " ('02', ('mswep', 'trmm')): {'R2': 0.9321551332270871},\n",
       " ('03', ('chirps', 'gpm')): {'R2': 0.7537432137583072},\n",
       " ('03', ('chirps', 'mswep')): {'R2': 0.8455371163069515},\n",
       " ('03', ('chirps', 'trmm')): {'R2': 0.7007273430903987},\n",
       " ('03', ('gpm', 'mswep')): {'R2': 0.9120727014302361},\n",
       " ('03', ('gpm', 'trmm')): {'R2': 0.8380646692561511},\n",
       " ('03', ('mswep', 'trmm')): {'R2': 0.736662498933492},\n",
       " ('04', ('chirps', 'gpm')): {'R2': 0.48580973327858823},\n",
       " ('04', ('chirps', 'mswep')): {'R2': 0.3788989300794695},\n",
       " ('04', ('chirps', 'trmm')): {'R2': 0.3931852636301968},\n",
       " ('04', ('gpm', 'mswep')): {'R2': 0.7613176582236729},\n",
       " ('04', ('gpm', 'trmm')): {'R2': 0.898369422720175},\n",
       " ('04', ('mswep', 'trmm')): {'R2': 0.8479115544133079},\n",
       " ('05', ('chirps', 'gpm')): {'R2': 0.17848141865711142},\n",
       " ('05', ('chirps', 'mswep')): {'R2': 0.020215794760533368},\n",
       " ('05', ('chirps', 'trmm')): {'R2': 0.0924691924701081},\n",
       " ('05', ('gpm', 'mswep')): {'R2': 0.13774202722486795},\n",
       " ('05', ('gpm', 'trmm')): {'R2': 0.5979651430233105},\n",
       " ('05', ('mswep', 'trmm')): {'R2': 0.00876896553780293},\n",
       " ('06', ('chirps', 'gpm')): {'R2': 0.042911327790571496},\n",
       " ('06', ('chirps', 'mswep')): {'R2': 0.1937164726577253},\n",
       " ('06', ('chirps', 'trmm')): {'R2': 0.20183292638501915},\n",
       " ('06', ('gpm', 'mswep')): {'R2': 0.7929430535564057},\n",
       " ('06', ('gpm', 'trmm')): {'R2': 0.7120088294317974},\n",
       " ('06', ('mswep', 'trmm')): {'R2': 0.964464586873632},\n",
       " ('07', ('chirps', 'gpm')): {'R2': 0.7926180341037803},\n",
       " ('07', ('chirps', 'mswep')): {'R2': 0.7946162450684355},\n",
       " ('07', ('chirps', 'trmm')): {'R2': 0.7857059316677812},\n",
       " ('07', ('gpm', 'mswep')): {'R2': 0.9322852206611733},\n",
       " ('07', ('gpm', 'trmm')): {'R2': 0.95875176093498},\n",
       " ('07', ('mswep', 'trmm')): {'R2': 0.9721468574817934},\n",
       " ('08', ('chirps', 'gpm')): {'R2': 0.8253463592753236},\n",
       " ('08', ('chirps', 'mswep')): {'R2': 0.832425434280761},\n",
       " ('08', ('chirps', 'trmm')): {'R2': 0.8312981561539374},\n",
       " ('08', ('gpm', 'mswep')): {'R2': 0.9091560853751028},\n",
       " ('08', ('gpm', 'trmm')): {'R2': 0.922027046589064},\n",
       " ('08', ('mswep', 'trmm')): {'R2': 0.9817177749886975},\n",
       " ('09', ('chirps', 'gpm')): {'R2': 0.24106283385625327},\n",
       " ('09', ('chirps', 'mswep')): {'R2': 0.33868748446082375},\n",
       " ('09', ('chirps', 'trmm')): {'R2': 0.3000059104044628},\n",
       " ('09', ('gpm', 'mswep')): {'R2': 0.7441725190649824},\n",
       " ('09', ('gpm', 'trmm')): {'R2': 0.7251639719887895},\n",
       " ('09', ('mswep', 'trmm')): {'R2': 0.893306432786508},\n",
       " ('10', ('chirps', 'gpm')): {'R2': 0.18182877017944166},\n",
       " ('10', ('chirps', 'mswep')): {'R2': 0.1780481789302546},\n",
       " ('10', ('chirps', 'trmm')): {'R2': 0.011961123490866643},\n",
       " ('10', ('gpm', 'mswep')): {'R2': 0.6378955342639605},\n",
       " ('10', ('gpm', 'trmm')): {'R2': 0.6925207620825212},\n",
       " ('10', ('mswep', 'trmm')): {'R2': 0.4359136651811495},\n",
       " ('11', ('chirps', 'gpm')): {'R2': 0.02355132378787117},\n",
       " ('11', ('chirps', 'mswep')): {'R2': 0.039485721846836075},\n",
       " ('11', ('chirps', 'trmm')): {'R2': 0.1537625903748241},\n",
       " ('11', ('gpm', 'mswep')): {'R2': 0.00833167376474242},\n",
       " ('11', ('gpm', 'trmm')): {'R2': 0.6516992150067086},\n",
       " ('11', ('mswep', 'trmm')): {'R2': 0.05931183892147707},\n",
       " ('12', ('chirps', 'gpm')): {'R2': 0.7480772223681198},\n",
       " ('12', ('chirps', 'mswep')): {'R2': 0.6481938056699779},\n",
       " ('12', ('chirps', 'trmm')): {'R2': 0.696079921185179},\n",
       " ('12', ('gpm', 'mswep')): {'R2': 0.9183603903133041},\n",
       " ('12', ('gpm', 'trmm')): {'R2': 0.8942095817858106},\n",
       " ('12', ('mswep', 'trmm')): {'R2': 0.8180835487225321}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_R2_month_pairs(p_m_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0986553",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Thanks for viewing!\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
