{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b1a666",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"0.1\"></a>\n",
    "# **Prior Uncertainty Quantification (UQ) tools**\n",
    "\n",
    "\n",
    "This notebook contains code examples to quantify uncertainties in precipitation data, including:\n",
    "1. [variability across products](#variability)\n",
    "1. [random errors in individual products](#randomerrors)\n",
    "1. [consistency between data pairs](#consistency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50604a7",
   "metadata": {},
   "source": [
    "<div><img src=\"UQ.png\" width=\"700\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3bb630",
   "metadata": {},
   "source": [
    "## import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df2fe9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmsmourad\\Anaconda3\\envs\\envs_sweo\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob  \n",
    "import gdal\n",
    "import shutil\n",
    "import rasterio as rio \n",
    "import itertools     \n",
    "from itertools import combinations \n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "#import watertools modules\n",
    "import watertools.General.raster_conversions as RC  \n",
    "import watertools.General.data_conversions as DC  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a99fc6e",
   "metadata": {},
   "source": [
    "# 1. variability across products <a class=\"anchor\" id=\"variability\"></a> \n",
    "[Uncertainty Quantification (UQ) tools](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ddf2f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file_info(f_path):\n",
    "    '''\n",
    "    this function gets geospatial information using a raster as a template\n",
    "\n",
    "    inputs:\n",
    "    ----------\n",
    "    - f_path : path to the location of the raster template (str)\n",
    "\n",
    "     outputs:\n",
    "    ----------\n",
    "    - geo_out: geospatial info\n",
    "    - proj: projection \n",
    "    - size_X: grid size in the X dimension\n",
    "    - size_Y: grid size in the Y dimension\n",
    "    \n",
    "    '''\n",
    "    in_fld = sorted(glob.glob(f_path + '\\*.tif')) \n",
    "    template = in_fld[0] \n",
    "    print(template)\n",
    "    \n",
    "    geo_out, proj, size_X, size_Y= RC.Open_array_info(template) #using watertools pkg\n",
    "\n",
    "    return geo_out, proj, size_X, size_Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c346b821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/p/chirps\\P_CHIRPS.v2.0_mm-month-1_monthly_2003.01.01.tif\n"
     ]
    }
   ],
   "source": [
    "f_path=r'../data/p/chirps'\n",
    "geo_out, proj, size_X, size_Y= extract_file_info(f_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7654921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_annual_avg(root_folder, syear, eyear,output_f):\n",
    "    \"\"\"\n",
    "    this function calculates the long-term annual average of tiff files \n",
    "\n",
    "    inputs:\n",
    "    ----------\n",
    "    - root_folder : path to the root folder (str)\n",
    "    - syear : start year(int) \n",
    "    - eyear : end year (int)\n",
    "    - output_f : location of the output folder (str)\n",
    "\n",
    "    \"\"\"\n",
    "   \n",
    "    for fx in os.listdir(root_folder):\n",
    "        fx_path = os.path.join(root_folder, fx) \n",
    "        if os.path.isdir(fx_path):\n",
    "            fx_sum_arr = None\n",
    "            files = []\n",
    "            num_yrs = eyear - syear + 1\n",
    "            for rx in os.listdir(fx_path):\n",
    "                rx_path = os.path.join(fx_path, rx)\n",
    "                dest_arr = gdal.Open(rx_path)\n",
    "                arr = dest_arr.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "                if fx_sum_arr is None:\n",
    "                    fx_sum_arr = np.zeros_like(arr)\n",
    "                fx_sum_arr += arr\n",
    "\n",
    "                files.append(rx_path)  \n",
    "\n",
    "            annual_avg = fx_sum_arr / num_yrs #long-term annual avg array \n",
    "            out_raster = os.path.join(output_f, f\"{subfolder}_longterm_avg.tif\")\n",
    "            DC.Save_as_tiff(out_raster, annual_avg,  geo_out, proj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bcc1894",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_f=r'../output_folder/longterm_avg/'\n",
    "root_folder=r'../data/p/'\n",
    "calc_annual_avg(root_folder,2003,2019,output_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd881f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cv(input_fhs, output_f, label=\"CV_p_mm-2003-2019.tif\"):\n",
    "    \"\"\"\n",
    "    this calculates the coefficient of variation (%) across a list long-term annual tiff files\n",
    "\n",
    "     inputs:\n",
    "    ----------\n",
    "    - input_fhs: List of file paths for input rasters  (list)\n",
    "    - output_f : path to the output folder (str)\n",
    "    - label: name of the output raster (str)\n",
    "    \"\"\"\n",
    "    arrs = []\n",
    "\n",
    "    for i in range(len(input_fhs)):\n",
    "        path_in = input_fhs[i]\n",
    "        print(path_in)\n",
    "        dest_arrs = gdal.Open(path_in)\n",
    "        arr = dest_arrs.GetRasterBand(1).ReadAsArray()\n",
    "        arrs.append(arr)\n",
    "        print(arr.shape)\n",
    "\n",
    "    arrs = np.array(arrs) \n",
    "    avg= np.mean(arrs, axis=0) \n",
    "    var = np.mean((arrs - avg) ** 2, axis=0) \n",
    "    std = np.sqrt(var) #std\n",
    "    cv = (std / avg) * 100 #CV(%)\n",
    "\n",
    "    fh_out = os.path.join(output_f, label)\n",
    "    DC.Save_as_tiff(fh_out, cv,  geo_out, proj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a7ec49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output_folder/longterm_avg\\chirps_longterm_avg.tif\n",
      "(37, 13)\n",
      "../output_folder/longterm_avg\\gpm_longterm_avg.tif\n",
      "(37, 13)\n",
      "../output_folder/longterm_avg\\mswep_longterm_avg.tif\n",
      "(37, 13)\n",
      "../output_folder/longterm_avg\\trmm_longterm_avg.tif\n",
      "(37, 13)\n"
     ]
    }
   ],
   "source": [
    "input_fhs=sorted(glob.glob(output_f+'\\*.tif'))\n",
    "output_cv=r'../output_folder/cv'\n",
    "calc_cv (input_fhs, output_cv, label=\"CV_p_mm-2003-2019.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6808341",
   "metadata": {},
   "source": [
    "# 2. random errors in individual products <a class=\"anchor\" id=\"randomerrors\"></a> \n",
    "[Uncertainty Quantification (UQ) tools](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "229e178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dirs(path_root):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    ----------\n",
    "    - path_root: path for dirs (str) \n",
    "    \n",
    "    outputs:\n",
    "    ----------\n",
    "    - list of dirs paths\n",
    "\n",
    "    \"\"\"\n",
    "    dirs_data = [os.path.join(path_root, dx) for dx in os.listdir(path_root)]\n",
    "    return dirs_data\n",
    "\n",
    "def make_dict_data(dirs_data):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    ----------\n",
    "    - dirs_data: list of data dirs paths\n",
    "    \n",
    "    outputs:\n",
    "    ----------\n",
    "    - dict_data: a dictionary with dir names as keys and file paths as values\n",
    "    - dict_ts: a dictionary of stacke timeseries data \n",
    "    \n",
    "    \"\"\"\n",
    "    dict_data = {}\n",
    "    dict_ts = {}\n",
    "\n",
    "\n",
    "    for dx in data_dirs:\n",
    "        fxs_list = [os.path.join(dx, f) for f in sorted(os.listdir(dx))] #list of files\n",
    "        dir_label= os.path.split(dx)[1]\n",
    "        dict_data[dir_label] = fxs_list\n",
    "        \n",
    "    #CHECK WHETHER ARRAYS HAVE CONSISTENT LENGTHS\n",
    "    leng = {label: len(paths) for label, paths in dict_data.items()}  \n",
    "    #print(leng) \n",
    "\n",
    "        \n",
    "    for k in data_dict.keys():\n",
    "        #print(k)\n",
    "        for fx in range(len(fxs_list)):\n",
    "            arr_3d = np.dstack([rio.open(d).read(1) for d in dict_data[k]])\n",
    "            dict_ts[k] = arr_3d\n",
    "    \n",
    "    return dict_data,dict_ts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ac61815",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs_data=list_dirs(\"../data/p/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43dc4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data,dict_ts=make_dict_data(dirs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "345b89af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_rescaling(source_dataset, ref_dataset):\n",
    "    '''\n",
    "    this function scales the source data set to the mean and std of a reference data set\n",
    "\n",
    "    inputs:\n",
    "    ----------\n",
    "    - source_dataset to be scaled \n",
    "    - ref_dataset to be used as template\n",
    "\n",
    "    outputs:\n",
    "    ----------\n",
    "    - scaled dataset\n",
    "    \n",
    "    references\n",
    "    ----------\n",
    "    linear rescaling Eq 2 in:\n",
    "    --Brocca, L., Melone, F., Moramarco, T., Wagner, W., & Hasenauer, S. (2010). \n",
    "      ASCAT soil wetness index validation through in situ and \n",
    "      modeled soil moisture data in central Italy. \n",
    "      Remote Sensing of Environment, 114(11), 2745-2755.\n",
    "      \n",
    "    other alternative rescaling options include: \n",
    "    - forcing source data set to have the same min and max as the ref data set\n",
    "    - matching the cumulative distribution function (CDF) of the source data set with that of ref data set\n",
    "    as in Eqs 6 & 7 in: \n",
    "    --Wu, K., Ryu, D., Wagner, W., & Hu, Z. (2023).\n",
    "      A global-scale intercomparison of Triple Collocation Analysis-and ground-based \n",
    "      soil moisture time-variant errors derived from different rescaling techniques.\n",
    "      Remote Sensing of Environment, 285, 113387.\n",
    "    \n",
    "    '''\n",
    "    return ((source_dataset - np.nanmean(source_dataset)) / np.nanstd(source_dataset)) * np.nanstd(ref_dataset) + np.nanmean(ref_dataset)\n",
    "\n",
    "\n",
    "def compute_random_errors(A,B,C):\n",
    "    '''\n",
    "    this function computes random errors as std of the noise error in individual products \n",
    "    \n",
    "    inputs:\n",
    "    ----------\n",
    "    - triplet data sets: A, B & C \n",
    "     where A, B and C are three spatially and temporally collocated data sets\n",
    "    \n",
    "    outputs:\n",
    "    ----------\n",
    "    - error std\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    std_A = np.sqrt(np.abs(np.nanmean((A - B) * (A - C))))\n",
    "    std_B = np.sqrt(np.abs(np.nanmean((B - A) * (B - C))))\n",
    "    std_C = np.sqrt(np.abs(np.nanmean((C - A) * (C - B))))\n",
    "\n",
    "    return std_A, std_B, std_C\n",
    "\n",
    "def compute_errs_combos(dict_ts, combos):\n",
    "    '''\n",
    "    this function computes errors for all combinations of triplets \n",
    "    a wrapper for compute_random_errors\n",
    "    \n",
    "    inputs:\n",
    "    ----------\n",
    "    - dict_ts:timeseries data (dict)\n",
    "    - combos: all possible combinations of triplets\n",
    "    \n",
    "    outputs:\n",
    "    ----------\n",
    "    - errors: spatial std of errors in individual product \n",
    "    \n",
    "    references\n",
    "    ----------\n",
    "    – To solve for the standard deciation, std is computed as proposed by Stoffelen (1998)** \n",
    "    – by averaging the cross-multiplied differences between the three a-priori rescaled data sets.\n",
    "    - Stoffelen (1998) also proposed other formulation based on combinations of the covariances\n",
    "      between the data sets. However, both approaches are mathematically identical.\n",
    "    \n",
    "    **Stoffelen, A. (1998). Toward the true near‐surface wind speed: Error modeling and calibration \n",
    "    using triple collocation.Journal of geophysical research: oceans, 103(C4), 7755-7766.\n",
    "    \n",
    "    '''\n",
    "    errs = {f'{map_combo[0]}_{z}': {\n",
    "                f'{map_combo[0]}_{z}': np.zeros_like(dict_ts[map_combo[0]][:, :, 0]),\n",
    "                f'{map_combo[1]}_{z}': np.zeros_like(dict_ts[map_combo[1]][:, :, 0]),\n",
    "                f'{map_combo[2]}_{z}': np.zeros_like(dict_ts[map_combo[2]][:, :, 0])} \n",
    "              for z, map_combo in enumerate(combos)}\n",
    "\n",
    "    for i in range(errs[f'{combos_labels[0]}_0'][f'{combos_labels[0]}_0'].shape[0]):\n",
    "        for j in range(errs[f'{combos_labels[0]}_0'][f'{combos_labels[0]}_0'].shape[1]):\n",
    "            for x, map_combo in enumerate(combos):\n",
    "                A_label = f'{map_combo[0]}_{x}'\n",
    "                val_A = dict_ts[map_combo[0]][i, j, :]\n",
    "                val_B = dict_ts[map_combo[1]][i, j, :]\n",
    "                val_C = dict_ts[map_combo[2]][i, j, :]\n",
    "                \n",
    "                std_A, std_B, std_C= compute_random_errors(val_A, linear_rescaling(val_B, val_A), linear_rescaling(val_C, val_A))\n",
    "                \n",
    "                errs[A_label][f'{map_combo[0]}_{x}'][i, j] = std_A\n",
    "                errs[A_label][f'{map_combo[1]}_{x}'][i, j] = std_B\n",
    "                errs[A_label][f'{map_combo[2]}_{x}'][i, j] = std_C\n",
    "\n",
    "    return errs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "346b6468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmsmourad\\Anaconda3\\envs\\envs_sweo\\lib\\site-packages\\ipykernel_launcher.py:32: RuntimeWarning: Mean of empty slice\n",
      "C:\\Users\\rmsmourad\\Anaconda3\\envs\\envs_sweo\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1671: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  keepdims=keepdims)\n",
      "C:\\Users\\rmsmourad\\Anaconda3\\envs\\envs_sweo\\lib\\site-packages\\ipykernel_launcher.py:51: RuntimeWarning: Mean of empty slice\n",
      "C:\\Users\\rmsmourad\\Anaconda3\\envs\\envs_sweo\\lib\\site-packages\\ipykernel_launcher.py:52: RuntimeWarning: Mean of empty slice\n",
      "C:\\Users\\rmsmourad\\Anaconda3\\envs\\envs_sweo\\lib\\site-packages\\ipykernel_launcher.py:53: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "combos_labels = ['chirps', 'gpm', 'mswep','trmm']  \n",
    "map_combo = list(itertools.permutations(combos_labels, 3))\n",
    "\n",
    "random_errors = compute_errs_combos(dict_ts, map_combo) #calc errors for all combos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f61c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_errors_to_tifs(out_f, random_errors):\n",
    "    '''\n",
    "    this function outputs errors to tiff files\n",
    "\n",
    "    inputs:\n",
    "    ----------\n",
    "    - out_f : output folder (str)\n",
    "    - random_errors (dict) \n",
    "\n",
    "    '''\n",
    "    for k,val in random_errors.items():\n",
    "        for arr_k, arr_data in val.items():\n",
    "            label_outfile = os.path.join(out_f, f\"{arr_k}.tif\")\n",
    "            DC.Save_as_tiff(label_outfile, arr_data, geo_out, proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "363c31b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder=r'../output_folder'\n",
    "save_errors_to_tifs(output_folder,random_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6d4cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_rasters_in_subfold(f_path, ext='.tif', extr=2):\n",
    "    '''\n",
    "    this function stores tiff files in subfolders using their labels\n",
    "\n",
    "    inputs:\n",
    "    ----------\n",
    "    - f_path : path to tiff files\n",
    "    - ext : tiff files extension (str)\n",
    "    - extr : characters extracted from the filelabel(int) \n",
    "\n",
    "    '''\n",
    "    for filelabel in os.listdir(f_path):\n",
    "        if filelabel.endswith(ext):\n",
    "            label= filelabel[:extr]\n",
    "            subfold = os.path.join(f_path, label)\n",
    "            os.makedirs(subfold, exist_ok=True)\n",
    "            shutil.move(os.path.join(f_path, filelabel), os.path.join(subfold, filelabel))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "626bad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_rasters_in_subfold(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "762a3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the subfolders\n",
    "\n",
    "for f_label in os.listdir(output_folder):\n",
    "    if f_label == 'ch':\n",
    "        os.rename(os.path.join(output_folder, f_label), os.path.join(output_folder, 'chirps'))\n",
    "    elif f_label == 'ms':\n",
    "        os.rename(os.path.join(output_folder, f_label), os.path.join(output_folder, 'mswep'))\n",
    "    elif f_label == 'tr':\n",
    "        os.rename(os.path.join(output_folder, f_label), os.path.join(output_folder, 'trmm'))\n",
    "    elif f_label == 'gp':\n",
    "        os.rename(os.path.join(output_folder, f_label), os.path.join(output_folder, 'gpm'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7396958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_error(root_folder):\n",
    "    '''\n",
    "    this function computes the average error for list of triple collocation error tiff files\n",
    "\n",
    "    inputs:\n",
    "    ----------\n",
    "    root_folder: path to the error tiff files (str)\n",
    "    \n",
    "    '''\n",
    "    for fhs_label in os.listdir(root_folder):\n",
    "        fhs = os.path.join(root_folder, fhs_label)\n",
    "\n",
    "        if os.path.isdir(fhs):\n",
    "            sum_arr = None\n",
    "            fr = []\n",
    "\n",
    "            for rx in os.listdir(fhs):\n",
    "                rx_path = os.path.join(fhs, rx)\n",
    "                #print(rx_path)\n",
    "                fr.append(rx_path)  # Append the raster file path to the list\n",
    "                img = gdal.Open(rx_path)  # Open the raster file\n",
    "                arr = img.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "                # update sum_arr\n",
    "                if sum_arr is None:\n",
    "                    sum_arr = np.zeros_like(arr)\n",
    "\n",
    "                sum_arr += arr\n",
    "\n",
    "            # calculate the avg\n",
    "            arr_avg = sum_arr / len(fr)\n",
    "\n",
    "            geo_out, proj, size_X, size_Y = extract_file_info(f_path)\n",
    "\n",
    "            # save output\n",
    "            output_label = os.path.join(fhs, f\"TC_{fhs_label}_avg.tif\")\n",
    "            DC.Save_as_tiff(output_label, arr_avg, geo_out, proj)  # Save raster \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a0cad3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/p/chirps\\P_CHIRPS.v2.0_mm-month-1_monthly_2003.01.01.tif\n",
      "../data/p/chirps\\P_CHIRPS.v2.0_mm-month-1_monthly_2003.01.01.tif\n",
      "../data/p/chirps\\P_CHIRPS.v2.0_mm-month-1_monthly_2003.01.01.tif\n",
      "../data/p/chirps\\P_CHIRPS.v2.0_mm-month-1_monthly_2003.01.01.tif\n",
      "../data/p/chirps\\P_CHIRPS.v2.0_mm-month-1_monthly_2003.01.01.tif\n",
      "../data/p/chirps\\P_CHIRPS.v2.0_mm-month-1_monthly_2003.01.01.tif\n"
     ]
    }
   ],
   "source": [
    "compute_avg_error(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8736a9f",
   "metadata": {},
   "source": [
    "# 3. consistency between data pairs <a class=\"anchor\" id=\"consistency\"></a> \n",
    "[Uncertainty Quantification (UQ) tools](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52eba689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_monthly_avg(r_f, outf_p, syear, eyear):\n",
    "    \"\"\"\n",
    "    this function computes the long-term monthly average of tiff files\n",
    "\n",
    "    inputs:\n",
    "    ----------\n",
    "    - r_f: path to the root folder (str)\n",
    "    - outf_p : output folder to store avg monthly tiff files(str)\n",
    "    - syear : start year(int)\n",
    "    - eyear : end year(int)\n",
    "    \"\"\"\n",
    "    yrs_nb = eyear - syear + 1\n",
    "    mths = range(1, 13)\n",
    "\n",
    "    for subf_label in os.listdir(r_f):\n",
    "        fhs = os.path.join(r_f, subf_label)\n",
    "\n",
    "        if os.path.isdir(fhs):\n",
    "            m_avgs = {}\n",
    "\n",
    "            for rx in os.listdir(fhs):\n",
    "                rx_path = os.path.join(fhs, rx)\n",
    "\n",
    "                dest_arr = gdal.Open(rx_path)\n",
    "                arr = dest_arr.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "                m = int(rx[-9:-7])\n",
    "                #print(m)\n",
    "\n",
    "                # aggregate\n",
    "                if m in m_avgs:\n",
    "                    m_avgs[m].append(arr)\n",
    "                else:\n",
    "                    m_avgs[m] = [arr]\n",
    "                    \n",
    "            fhs_output= os.path.join(outf_p, subf_label)\n",
    "            os.makedirs(fhs_output, exist_ok=True)\n",
    "\n",
    "            for m,x in m_avgs.items():\n",
    "                m_mean = np.mean(x, axis=0)\n",
    "                output_label = os.path.join(fhs_output, f'{subf_label}_avg_{m:02d}.tif')\n",
    "                DC.Save_as_tiff(output_label, m_mean, geo_out, proj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c591d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "outf_p=r'../output_folder/monthly_longterm_avg'\n",
    "compute_monthly_avg(root_folder, outf_p, 2003, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70f25d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Row  Column  TC_longterm_avg_avg_Value  chirps_longterm_avg_Value  \\\n",
      "11     0      11                1511.161743                1419.767944   \n",
      "23     1      10                1444.936768                1418.300415   \n",
      "24     1      11                1464.628784                1412.772095   \n",
      "35     2       9                1344.553101                1263.947266   \n",
      "36     2      10                1372.688354                1311.729492   \n",
      "..   ...     ...                        ...                        ...   \n",
      "446   34       4                 828.751221                 861.020447   \n",
      "447   34       5                 831.144226                 852.607117   \n",
      "459   35       4                 814.133545                 836.936707   \n",
      "460   35       5                 816.694214                 828.406128   \n",
      "472   36       4                 808.455078                 844.302917   \n",
      "\n",
      "     gpm_longterm_avg_Value  mswep_longterm_avg_Value  trmm_longterm_avg_Value  \n",
      "11              1466.187256               1691.985840              1466.706055  \n",
      "23              1406.040405               1555.549072              1399.857178  \n",
      "24              1427.168335               1593.652222              1424.922241  \n",
      "35              1352.552368               1436.383301              1325.329468  \n",
      "36              1375.716553               1451.154053              1352.153320  \n",
      "..                      ...                       ...                      ...  \n",
      "446              884.860962                839.233337               729.890198  \n",
      "447              885.286377                850.931396               735.752014  \n",
      "459              868.385193                824.186279               727.025879  \n",
      "460              870.664612                835.187805               732.518372  \n",
      "472              854.458740                810.452820               724.605774  \n",
      "\n",
      "[221 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#extract pixel by pixel value from long-term annual rasters\n",
    "# df\n",
    "output_f=r'../output_folder/longterm_avg/'\n",
    "output_f_p=sorted(glob.glob(output_f+'\\*.tif')) #get list of tif files in the output_f folder\n",
    "df = pd.DataFrame(columns=['row', 'col'] + [os.path.splitext(os.path.basename(rx))[0] + '_val' for rx in output_f_p], dtype='object')\n",
    "\n",
    "for i, rx in enumerate(output_f_p):\n",
    "    #print(raster_file)\n",
    "    # Open the raster file\n",
    "    img = gdal.Open(rx)\n",
    "    data = dataset.GetRasterBand(1).ReadAsArray()  \n",
    "    idx, jdx = data.shape\n",
    "    i_ind, j_ind = zip(*[(i, j) for i in range(idx) for j in range(jdx)])\n",
    "    \n",
    "    rx_label = os.path.splitext(os.path.basename(rx))[0]\n",
    "    df[f'{rx_label}_Value'] = data.flatten()\n",
    "    df['row'] = i_ind\n",
    "    df['col'] = j_ind \n",
    "\n",
    "df_annual = df[['row', 'col'] + [f'{os.path.splitext(os.path.basename(rx))[0]}_val' for rx in output_f_p]]\n",
    "df_annual=df_annual.dropna()\n",
    "print(df_annual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2eef4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable  Row  Column Month  chirps_Value   gpm_Value  mswep_Value  trmm_Value\n",
      "0           0      11    01     37.980194   59.296268    41.447906   62.900562\n",
      "1           0      11    02     46.546810   46.641949    49.457249   61.216122\n",
      "2           0      11    03     44.627464   43.122429    38.775211   40.940529\n",
      "3           0      11    04     21.511442   30.202278    26.348068   32.613499\n",
      "4           0      11    05     30.734367   39.504498    36.736843   36.886265\n",
      "...       ...     ...   ...           ...         ...          ...         ...\n",
      "2647       36       4    08    240.456375  231.957382   218.106476  180.060471\n",
      "2648       36       4    09    180.250015  155.690353   127.589195  123.292252\n",
      "2649       36       4    10     20.838272   18.132835    15.366764   17.345371\n",
      "2650       36       4    11      3.061043    5.250890     4.227652    3.091552\n",
      "2651       36       4    12      7.615210    3.761159     4.948952    3.583566\n",
      "\n",
      "[2652 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#extract pixel by pixel value from long-term monthly rasters\n",
    "outfolder_P = r'../output_folder/monthly_longterm_avg'\n",
    "list_data = []\n",
    "# Loop over subfolders in the main folder\n",
    "for fhs in os.listdir(outfolder_P):\n",
    "    fhs_path = os.path.join(outfolder_P, fhs)\n",
    "    rx_data = sorted(glob.glob(os.path.join(fhs_path, '*.tif')))\n",
    "\n",
    "    for i, rx in enumerate(rx_data):\n",
    "        img = gdal.Open(rx)\n",
    "        data= dataset.GetRasterBand(1).ReadAsArray()\n",
    "        idx, jdx = data.shape\n",
    "        i_ind, j_ind = zip(*[(i, j) for i in range(idx) for j in range(jdx)])\n",
    "        m = os.path.splitext(os.path.basename(raster))[0][-2:] #extract month\n",
    "        list_data.extend(list(zip(i_ind, j_ind, [m] * len(i_ind), [f'{fhs}_val'] * len(i_ind), data.flatten())))\n",
    "\n",
    "# df\n",
    "col_labels = ['row', 'col', 'month', 'var', 'val']\n",
    "df_month = pd.DataFrame(list_data, columns=col_labels)\n",
    "df_month = df_month.pivot_table(index=['row', 'col', 'month'], columns='var', values='val').reset_index()\n",
    "print(df_month.dropna())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0006f8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spatial_R2(A, B):\n",
    "    A = np.array(A)\n",
    "    B = np.array(B)\n",
    "    a, b = np.polyfit(A, B, 1)\n",
    "    B_pred = a * x + b\n",
    "    R2 = r2_score(B, B_pred)\n",
    "    return {'R2': R2}\n",
    "\n",
    "def do_R2_annual_pairs(df):\n",
    "    \n",
    "    dict_yr = df.astype(float).to_dict('list') \n",
    "    combos = list(itertools.combinations(dict_yr, 2))\n",
    "\n",
    "    res = {}\n",
    "\n",
    "    for idx, i in enumerate(combos):\n",
    "        A = dict_yr[i[0]]\n",
    "        B = dict_yr[i[1]]\n",
    "        R2_metric = compute_spatial_R2(A, B)\n",
    "        res[i] = R2_metric\n",
    "    return res\n",
    "\n",
    "def do_R2_month_pairs(df):\n",
    "    '''\n",
    "    this function computes R2 metric by a month column applied to df\n",
    "    '''\n",
    "    res = {}\n",
    "\n",
    "    # Group the data by month column\n",
    "    m_grp = df.groupby('Month')\n",
    "    for m, grp in m_grp:\n",
    "        dict_m = grp.astype(float).to_dict('list')\n",
    "        combos = list(itertools.combinations(dict_m, 2))\n",
    "        for idx, i in enumerate(combos):\n",
    "            A = dict_m[i[0]]\n",
    "            B = dict_m[i[1]]\n",
    "            R2_metric = compute_spatial_R2(A, B)\n",
    "            # Store the metrics with the month identifier\n",
    "            res[(m, i)] = R2_metric\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48e588cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmsmourad\\Anaconda3\\envs\\envs_sweo\\lib\\site-packages\\pandas\\core\\frame.py:4223: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chirps</th>\n",
       "      <th>gpm</th>\n",
       "      <th>mswep</th>\n",
       "      <th>trmm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1419.767944</td>\n",
       "      <td>1466.187256</td>\n",
       "      <td>1691.985840</td>\n",
       "      <td>1466.706055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1418.300415</td>\n",
       "      <td>1406.040405</td>\n",
       "      <td>1555.549072</td>\n",
       "      <td>1399.857178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1412.772095</td>\n",
       "      <td>1427.168335</td>\n",
       "      <td>1593.652222</td>\n",
       "      <td>1424.922241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1263.947266</td>\n",
       "      <td>1352.552368</td>\n",
       "      <td>1436.383301</td>\n",
       "      <td>1325.329468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1311.729492</td>\n",
       "      <td>1375.716553</td>\n",
       "      <td>1451.154053</td>\n",
       "      <td>1352.153320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>446</td>\n",
       "      <td>861.020447</td>\n",
       "      <td>884.860962</td>\n",
       "      <td>839.233337</td>\n",
       "      <td>729.890198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>447</td>\n",
       "      <td>852.607117</td>\n",
       "      <td>885.286377</td>\n",
       "      <td>850.931396</td>\n",
       "      <td>735.752014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>459</td>\n",
       "      <td>836.936707</td>\n",
       "      <td>868.385193</td>\n",
       "      <td>824.186279</td>\n",
       "      <td>727.025879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>828.406128</td>\n",
       "      <td>870.664612</td>\n",
       "      <td>835.187805</td>\n",
       "      <td>732.518372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472</td>\n",
       "      <td>844.302917</td>\n",
       "      <td>854.458740</td>\n",
       "      <td>810.452820</td>\n",
       "      <td>724.605774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          chirps          gpm        mswep         trmm\n",
       "11   1419.767944  1466.187256  1691.985840  1466.706055\n",
       "23   1418.300415  1406.040405  1555.549072  1399.857178\n",
       "24   1412.772095  1427.168335  1593.652222  1424.922241\n",
       "35   1263.947266  1352.552368  1436.383301  1325.329468\n",
       "36   1311.729492  1375.716553  1451.154053  1352.153320\n",
       "..           ...          ...          ...          ...\n",
       "446   861.020447   884.860962   839.233337   729.890198\n",
       "447   852.607117   885.286377   850.931396   735.752014\n",
       "459   836.936707   868.385193   824.186279   727.025879\n",
       "460   828.406128   870.664612   835.187805   732.518372\n",
       "472   844.302917   854.458740   810.452820   724.605774\n",
       "\n",
       "[221 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_yr_dict = {'chirps_longterm_avg_val':'chirps',\n",
    "             'gpm_longterm_avg_val': 'gpm',\n",
    "             'mswep_longterm_avg_val':'mswep', \n",
    "             'trmm_longterm_avg_val':'trmm'}\n",
    "    \n",
    "p_yr_df= df_annual.loc[:, df_annual.columns.isin(p_yr_dict.keys())]\n",
    "p_yr_df.rename(columns = p_yr_dict, inplace = True)\n",
    "p_yr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c37251e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chirps</th>\n",
       "      <th>gpm</th>\n",
       "      <th>mswep</th>\n",
       "      <th>trmm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1419.767944</td>\n",
       "      <td>1466.187256</td>\n",
       "      <td>1691.985840</td>\n",
       "      <td>1466.706055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1418.300415</td>\n",
       "      <td>1406.040405</td>\n",
       "      <td>1555.549072</td>\n",
       "      <td>1399.857178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1412.772095</td>\n",
       "      <td>1427.168335</td>\n",
       "      <td>1593.652222</td>\n",
       "      <td>1424.922241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1263.947266</td>\n",
       "      <td>1352.552368</td>\n",
       "      <td>1436.383301</td>\n",
       "      <td>1325.329468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1311.729492</td>\n",
       "      <td>1375.716553</td>\n",
       "      <td>1451.154053</td>\n",
       "      <td>1352.153320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>446</td>\n",
       "      <td>861.020447</td>\n",
       "      <td>884.860962</td>\n",
       "      <td>839.233337</td>\n",
       "      <td>729.890198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>447</td>\n",
       "      <td>852.607117</td>\n",
       "      <td>885.286377</td>\n",
       "      <td>850.931396</td>\n",
       "      <td>735.752014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>459</td>\n",
       "      <td>836.936707</td>\n",
       "      <td>868.385193</td>\n",
       "      <td>824.186279</td>\n",
       "      <td>727.025879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>828.406128</td>\n",
       "      <td>870.664612</td>\n",
       "      <td>835.187805</td>\n",
       "      <td>732.518372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472</td>\n",
       "      <td>844.302917</td>\n",
       "      <td>854.458740</td>\n",
       "      <td>810.452820</td>\n",
       "      <td>724.605774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          chirps          gpm        mswep         trmm\n",
       "11   1419.767944  1466.187256  1691.985840  1466.706055\n",
       "23   1418.300415  1406.040405  1555.549072  1399.857178\n",
       "24   1412.772095  1427.168335  1593.652222  1424.922241\n",
       "35   1263.947266  1352.552368  1436.383301  1325.329468\n",
       "36   1311.729492  1375.716553  1451.154053  1352.153320\n",
       "..           ...          ...          ...          ...\n",
       "446   861.020447   884.860962   839.233337   729.890198\n",
       "447   852.607117   885.286377   850.931396   735.752014\n",
       "459   836.936707   868.385193   824.186279   727.025879\n",
       "460   828.406128   870.664612   835.187805   732.518372\n",
       "472   844.302917   854.458740   810.452820   724.605774\n",
       "\n",
       "[221 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_yr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "600eb547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('chirps', 'gpm'): {'R2': 0.8135627226312636},\n",
       " ('chirps', 'mswep'): {'R2': 0.8609587106575535},\n",
       " ('chirps', 'trmm'): {'R2': 0.8348135971608387},\n",
       " ('gpm', 'mswep'): {'R2': 0.9324395699548236},\n",
       " ('gpm', 'trmm'): {'R2': 0.9586354670725602},\n",
       " ('mswep', 'trmm'): {'R2': 0.9807891795543765}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_R2_annual_pairs(p_yr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "305cb4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmsmourad\\Anaconda3\\envs\\envs_sweo\\lib\\site-packages\\pandas\\core\\frame.py:4223: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Variable</th>\n",
       "      <th>chirps</th>\n",
       "      <th>gpm</th>\n",
       "      <th>mswep</th>\n",
       "      <th>trmm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>01</td>\n",
       "      <td>37.980194</td>\n",
       "      <td>59.296268</td>\n",
       "      <td>41.447906</td>\n",
       "      <td>62.900562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>02</td>\n",
       "      <td>46.546810</td>\n",
       "      <td>46.641949</td>\n",
       "      <td>49.457249</td>\n",
       "      <td>61.216122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>03</td>\n",
       "      <td>44.627464</td>\n",
       "      <td>43.122429</td>\n",
       "      <td>38.775211</td>\n",
       "      <td>40.940529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>04</td>\n",
       "      <td>21.511442</td>\n",
       "      <td>30.202278</td>\n",
       "      <td>26.348068</td>\n",
       "      <td>32.613499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>05</td>\n",
       "      <td>30.734367</td>\n",
       "      <td>39.504498</td>\n",
       "      <td>36.736843</td>\n",
       "      <td>36.886265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>08</td>\n",
       "      <td>240.456375</td>\n",
       "      <td>231.957382</td>\n",
       "      <td>218.106476</td>\n",
       "      <td>180.060471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>09</td>\n",
       "      <td>180.250015</td>\n",
       "      <td>155.690353</td>\n",
       "      <td>127.589195</td>\n",
       "      <td>123.292252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>20.838272</td>\n",
       "      <td>18.132835</td>\n",
       "      <td>15.366764</td>\n",
       "      <td>17.345371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.061043</td>\n",
       "      <td>5.250890</td>\n",
       "      <td>4.227652</td>\n",
       "      <td>3.091552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>7.615210</td>\n",
       "      <td>3.761159</td>\n",
       "      <td>4.948952</td>\n",
       "      <td>3.583566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2652 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Variable      chirps         gpm       mswep        trmm\n",
       "Month                                                   \n",
       "01         37.980194   59.296268   41.447906   62.900562\n",
       "02         46.546810   46.641949   49.457249   61.216122\n",
       "03         44.627464   43.122429   38.775211   40.940529\n",
       "04         21.511442   30.202278   26.348068   32.613499\n",
       "05         30.734367   39.504498   36.736843   36.886265\n",
       "...              ...         ...         ...         ...\n",
       "08        240.456375  231.957382  218.106476  180.060471\n",
       "09        180.250015  155.690353  127.589195  123.292252\n",
       "10         20.838272   18.132835   15.366764   17.345371\n",
       "11          3.061043    5.250890    4.227652    3.091552\n",
       "12          7.615210    3.761159    4.948952    3.583566\n",
       "\n",
       "[2652 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_m_dict = {'chirps_val':'chirps',\n",
    "             'gpm_val': 'gpm',\n",
    "             'mswep_val':'mswep', \n",
    "             'trmm_val':'trmm',\n",
    "             'Month':'Month'}\n",
    "    \n",
    "p_m_df= df_month.loc[:, df_month.columns.isin(p_m_dict.keys())]\n",
    "p_m_df.rename(columns = p_m_dict, inplace = True)\n",
    "p_m_df.set_index('Month', inplace=True)\n",
    "p_m_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51c9fd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('01', ('chirps', 'gpm')): {'R2': 0.9117175286718363},\n",
       " ('01', ('chirps', 'mswep')): {'R2': 0.8380546776097375},\n",
       " ('01', ('chirps', 'trmm')): {'R2': 0.7100072575704479},\n",
       " ('01', ('gpm', 'mswep')): {'R2': 0.9577343308996298},\n",
       " ('01', ('gpm', 'trmm')): {'R2': 0.88628341450711},\n",
       " ('01', ('mswep', 'trmm')): {'R2': 0.9653490403385048},\n",
       " ('02', ('chirps', 'gpm')): {'R2': 0.7156481479525514},\n",
       " ('02', ('chirps', 'mswep')): {'R2': 0.7182623047381882},\n",
       " ('02', ('chirps', 'trmm')): {'R2': 0.812094451266089},\n",
       " ('02', ('gpm', 'mswep')): {'R2': 0.9227742258887887},\n",
       " ('02', ('gpm', 'trmm')): {'R2': 0.9412955107613685},\n",
       " ('02', ('mswep', 'trmm')): {'R2': 0.9321550757117292},\n",
       " ('03', ('chirps', 'gpm')): {'R2': 0.753743175250468},\n",
       " ('03', ('chirps', 'mswep')): {'R2': 0.8455371444033513},\n",
       " ('03', ('chirps', 'trmm')): {'R2': 0.7007272578822251},\n",
       " ('03', ('gpm', 'mswep')): {'R2': 0.9120727363508384},\n",
       " ('03', ('gpm', 'trmm')): {'R2': 0.8380646035254438},\n",
       " ('03', ('mswep', 'trmm')): {'R2': 0.7366624911719304},\n",
       " ('04', ('chirps', 'gpm')): {'R2': 0.4858097402572571},\n",
       " ('04', ('chirps', 'mswep')): {'R2': 0.3788989990798022},\n",
       " ('04', ('chirps', 'trmm')): {'R2': 0.3931852975575172},\n",
       " ('04', ('gpm', 'mswep')): {'R2': 0.7613176566046975},\n",
       " ('04', ('gpm', 'trmm')): {'R2': 0.8983694168984819},\n",
       " ('04', ('mswep', 'trmm')): {'R2': 0.8479115748804547},\n",
       " ('05', ('chirps', 'gpm')): {'R2': 0.17848132544923068},\n",
       " ('05', ('chirps', 'mswep')): {'R2': 0.02021580982738269},\n",
       " ('05', ('chirps', 'trmm')): {'R2': 0.09246917286991385},\n",
       " ('05', ('gpm', 'mswep')): {'R2': 0.13774206203669304},\n",
       " ('05', ('gpm', 'trmm')): {'R2': 0.5979652056412801},\n",
       " ('05', ('mswep', 'trmm')): {'R2': 0.008768961953088295},\n",
       " ('06', ('chirps', 'gpm')): {'R2': 0.042911328460794596},\n",
       " ('06', ('chirps', 'mswep')): {'R2': 0.1937165041270673},\n",
       " ('06', ('chirps', 'trmm')): {'R2': 0.2018329715181859},\n",
       " ('06', ('gpm', 'mswep')): {'R2': 0.792943008353504},\n",
       " ('06', ('gpm', 'trmm')): {'R2': 0.7120087665637357},\n",
       " ('06', ('mswep', 'trmm')): {'R2': 0.9644645870884747},\n",
       " ('07', ('chirps', 'gpm')): {'R2': 0.7926179934959858},\n",
       " ('07', ('chirps', 'mswep')): {'R2': 0.7946162796780927},\n",
       " ('07', ('chirps', 'trmm')): {'R2': 0.7857059568348284},\n",
       " ('07', ('gpm', 'mswep')): {'R2': 0.9322852422615804},\n",
       " ('07', ('gpm', 'trmm')): {'R2': 0.9587517560387244},\n",
       " ('07', ('mswep', 'trmm')): {'R2': 0.9721468499455743},\n",
       " ('08', ('chirps', 'gpm')): {'R2': 0.8253463510861838},\n",
       " ('08', ('chirps', 'mswep')): {'R2': 0.832425361709765},\n",
       " ('08', ('chirps', 'trmm')): {'R2': 0.8312981182011887},\n",
       " ('08', ('gpm', 'mswep')): {'R2': 0.9091560402003769},\n",
       " ('08', ('gpm', 'trmm')): {'R2': 0.9220270373560695},\n",
       " ('08', ('mswep', 'trmm')): {'R2': 0.9817177608354579},\n",
       " ('09', ('chirps', 'gpm')): {'R2': 0.24106277214392036},\n",
       " ('09', ('chirps', 'mswep')): {'R2': 0.3386873114667236},\n",
       " ('09', ('chirps', 'trmm')): {'R2': 0.30000563421486015},\n",
       " ('09', ('gpm', 'mswep')): {'R2': 0.744172563877491},\n",
       " ('09', ('gpm', 'trmm')): {'R2': 0.7251640766878611},\n",
       " ('09', ('mswep', 'trmm')): {'R2': 0.8933064452483269},\n",
       " ('10', ('chirps', 'gpm')): {'R2': 0.181828779954873},\n",
       " ('10', ('chirps', 'mswep')): {'R2': 0.17804824162167343},\n",
       " ('10', ('chirps', 'trmm')): {'R2': 0.011961123032327992},\n",
       " ('10', ('gpm', 'mswep')): {'R2': 0.6378954643032569},\n",
       " ('10', ('gpm', 'trmm')): {'R2': 0.692520748320604},\n",
       " ('10', ('mswep', 'trmm')): {'R2': 0.43591362843378434},\n",
       " ('11', ('chirps', 'gpm')): {'R2': 0.023551317960836315},\n",
       " ('11', ('chirps', 'mswep')): {'R2': 0.039485687989058715},\n",
       " ('11', ('chirps', 'trmm')): {'R2': 0.15376260279085074},\n",
       " ('11', ('gpm', 'mswep')): {'R2': 0.008331697584881503},\n",
       " ('11', ('gpm', 'trmm')): {'R2': 0.6516991887758925},\n",
       " ('11', ('mswep', 'trmm')): {'R2': 0.059311873777795565},\n",
       " ('12', ('chirps', 'gpm')): {'R2': 0.7480772379629013},\n",
       " ('12', ('chirps', 'mswep')): {'R2': 0.648193825386475},\n",
       " ('12', ('chirps', 'trmm')): {'R2': 0.6960799635497743},\n",
       " ('12', ('gpm', 'mswep')): {'R2': 0.9183603924491661},\n",
       " ('12', ('gpm', 'trmm')): {'R2': 0.8942095977547057},\n",
       " ('12', ('mswep', 'trmm')): {'R2': 0.8180835589928059}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_R2_month_pairs(p_m_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0986553",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Thanks for viewing!\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
